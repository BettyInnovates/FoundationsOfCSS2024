{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01196ea9-5dff-4279-b0a7-d9ea286e0c19",
   "metadata": {},
   "source": [
    "# Social Network Analysis of Swiss Politicians on Twitter Data\n",
    "## Tasks\n",
    "In this assignment you will do the following tasks:\n",
    "1. Construct the timelines of Twitter users\n",
    "2. Build social network of retweets\n",
    "3. Calculate assortativity\n",
    "4. Permutation tests\n",
    "5. Community detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aac7b3",
   "metadata": {},
   "source": [
    "### Install requirements. \n",
    "\n",
    "The following cell contains all the necessary dependencies needed for this task. If you run the cell everything will be installed.  \n",
    "\n",
    "* [`pandas`](https://pandas.pydata.org/docs/index.html) is a Python package for creating and working with tabular data. [Here](https://pandas.pydata.org/docs/reference/index.html) is the documentation of `pandas`.\n",
    "* [`numpy`](https://numpy.org/) is a Python package for mathematical functions. [Here](https://numpy.org/doc/stable/reference/index.html) is the documentation of `numpy`.\n",
    "* [`matplotlib`](https://matplotlib.org/) is a Python package for creating plots. [Here](https://matplotlib.org/stable/api/index.html) is the documentation of `matplotlib`.\n",
    "* [`networkx`](https://networkx.org/) is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks. [Here](https://networkx.org/documentation/stable/reference/index.html) is the documentation of `networkx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "234eb790-6def-45a2-b436-406eb1be62ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas\n",
    "# ! pip install numpy\n",
    "# ! pip install matplotlib\n",
    "# ! pip install networkx\n",
    "# ! pip install praw\n",
    "\n",
    "# added for zipfile\n",
    "# ! pip install zipfile36 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebb2e59",
   "metadata": {},
   "source": [
    "### Import requirements\n",
    "The cell below imports all necessary dependancies. Make sure they are installed (see cell above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e909d35-ff4c-45fc-8642-c2be8d3850c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timezone\n",
    "import zipfile # added to open zip-file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89432616-10db-4283-997c-90a243f41f60",
   "metadata": {},
   "source": [
    "# 1. Construct the timelines of Twitter users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b451349f-8eec-4534-8057-6e491546c024",
   "metadata": {},
   "source": [
    "You can use the provided `users.csv` file since Twitter API is unavailable at the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17226c56-e6cb-4354-b3d7-be2f38345c89",
   "metadata": {},
   "source": [
    "**Note:** Since Twitter API is currently unavailable, we also provide a `timelines.csv` file for you that includes tweets from July 5 to July 12. You can find it in the ZIP file, so please unzip it before using."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660c2bf5-29c6-451e-af54-893849528056",
   "metadata": {},
   "source": [
    "# 2. Build social networks of retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df9e2ad",
   "metadata": {},
   "source": [
    "Make sure to first load the timelines and users from the files, parse the creation date as datetime and convert the IDs to strings to avoid int overflows. Use `pandas` [`read_csv`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) to do so. Especially look at the keyword arguments `dtype` and `parse_dates`.\n",
    "\n",
    " Since the `referenced_tweets` field contains a list of dictionaries that is stored as a string, we need to parse it first to restore its structure as list of dictionaries to interact with it. For this you can use a combination of pythons [`eval`](https://docs.python.org/3/library/functions.html#eval) function and `pandas` [`apply`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html) method. This function takes a string and evaluates it as a python expression. For example if you have following String:\n",
    "```\n",
    "some_string_with_a_dict = '{\"first_key\": \"first_value\",\n",
    "                            \"second_key\": \"second_value\",\n",
    "                            \"third_key\": \"third_value\",}'\n",
    "```\n",
    "And use `eval` on it like the following:\n",
    "```\n",
    "usable_dictionary_from_string = eval(some_string_with_a_dict)\n",
    "```\n",
    "You get the dictionary as a python local usable dictonary. Try it out!\n",
    "Now you can convert every `\"referenced_tweets\"` field in the dataset to usable python expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "731d605d-3e1c-4237-8442-6fcb73074dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading timelines zip file\n",
    "zip_file = zipfile.ZipFile('timelines.zip')\n",
    "\n",
    "# load timelines and users from file\n",
    "timelines = pd.read_csv(\n",
    "    #\"timelines.csv\",\n",
    "    zip_file.open(\"timelines.csv\"),\n",
    "    dtype={\"id\":str, \"author_id\":str, \"conversation_id\":str}, # load all IDs as string to prevent long integer overflows\n",
    "    parse_dates=[\"created_at\"], # parse the tweet creation date as datetime\n",
    "    low_memory=False\n",
    ")\n",
    "users = pd.read_csv(\n",
    "    \"users.csv\",\n",
    "    dtype={\"id\":str},\n",
    "    parse_dates=[\"created_at\"]\n",
    ")\n",
    "\n",
    "# since the referenced_tweets field contains a list of dictionaries that is \n",
    "# stored as a string, we need to parse it first to restore its structure as\n",
    "# list of dictionaries to interact with it\n",
    "timelines[\"referenced_tweets\"] = timelines[\"referenced_tweets\"]\\\n",
    "    .apply(lambda x: eval(x) if x == x else np.nan)\n",
    "\n",
    "# timelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b19bc048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'retweeted',\n",
       "  'id': '1546388828667006977',\n",
       "  'reply_settings': 'everyone',\n",
       "  'conversation_id': '1546388828667006977',\n",
       "  'author_id': '1391450099205779456',\n",
       "  'text': 'Am 23. Dezember 1983 fand am @zrh_airport eine PK der El Al statt. Leider wissen wir (noch) nicht mehr über den Inhalt der PK. Wer erkennt Personen auf den Bildern?\\nHeute im #Blog #Crowdsourcing #WerWeissMehr\\nhttps://t.co/GGIk9ne4KI https://t.co/6OBB5pJQkh',\n",
       "  'source': 'Twitter Web App',\n",
       "  'entities': {'mentions': [{'start': 29,\n",
       "     'end': 41,\n",
       "     'username': 'zrh_airport',\n",
       "     'id': '282510542'}],\n",
       "   'urls': [{'start': 209,\n",
       "     'end': 232,\n",
       "     'url': 'https://t.co/GGIk9ne4KI',\n",
       "     'expanded_url': 'https://doi.org/10.35016/ethz-cs-22047-de',\n",
       "     'display_url': 'doi.org/10.35016/ethz-…',\n",
       "     'images': [{'url': 'https://pbs.twimg.com/news_img/1546388847239393282/zpkF2DzQ?format=jpg&name=orig',\n",
       "       'width': 2000,\n",
       "       'height': 1000},\n",
       "      {'url': 'https://pbs.twimg.com/news_img/1546388847239393282/zpkF2DzQ?format=jpg&name=150x150',\n",
       "       'width': 150,\n",
       "       'height': 150}],\n",
       "     'status': 200,\n",
       "     'title': 'Die Fluggesellschaft El Al am Flughafen Zürich - ETH-Bibliothek | Crowdsourcing',\n",
       "     'description': 'Lesezeit: 2 Min. Am 23. Dezember 1983 fand am Flughafen Zürich-Kloten eine Pressekonferenz der El Al statt...',\n",
       "     'unwound_url': 'https://blogs.ethz.ch/crowdsourcing/2022/07/11/die-fluggesellschaft-el-al-am-flughafen-zuerich/'},\n",
       "    {'start': 233,\n",
       "     'end': 256,\n",
       "     'url': 'https://t.co/6OBB5pJQkh',\n",
       "     'expanded_url': 'https://twitter.com/ETHBildarchiv/status/1546388828667006977/photo/1',\n",
       "     'display_url': 'pic.twitter.com/6OBB5pJQkh',\n",
       "     'media_key': '3_1546383410716938241'}],\n",
       "   'hashtags': [{'start': 174, 'end': 179, 'tag': 'Blog'},\n",
       "    {'start': 180, 'end': 194, 'tag': 'Crowdsourcing'},\n",
       "    {'start': 195, 'end': 208, 'tag': 'WerWeissMehr'}]},\n",
       "  'public_metrics': {'retweet_count': 2,\n",
       "   'reply_count': 0,\n",
       "   'like_count': 6,\n",
       "   'quote_count': 1},\n",
       "  'created_at': '2022-07-11T07:00:01.000Z',\n",
       "  'lang': 'de',\n",
       "  'attachments': {'media_keys': ['3_1546383410716938241'], 'media': [{}]},\n",
       "  'context_annotations': [{'domain': {'id': '131',\n",
       "     'name': 'Unified Twitter Taxonomy',\n",
       "     'description': 'A taxonomy view into the Semantic Core knowledge graph'},\n",
       "    'entity': {'id': '1242909627395665920', 'name': 'Blogging'}},\n",
       "   {'domain': {'id': '131',\n",
       "     'name': 'Unified Twitter Taxonomy',\n",
       "     'description': 'A taxonomy view into the Semantic Core knowledge graph'},\n",
       "    'entity': {'id': '1278000653416099840', 'name': 'Writing'}}],\n",
       "  'possibly_sensitive': False,\n",
       "  'author': {}}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timelines.loc[0, \"referenced_tweets\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a987f77-803b-438a-8e00-d35786dd8ae4",
   "metadata": {},
   "source": [
    "The field `referenced_tweets` currently contains a list where each entry is a tweet object (since we requested the expansion on the field `referenced_tweets.id`.\n",
    "\n",
    "To construct our retweet network, we need to know (a) whether a tweet was a retweet and (b) the ID of the account that posted the tweet that was retweeted. Below we define two functions that help us extract this information from the `referenced_tweets` field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ce16548-973a-4d78-90d9-7111e8c9f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_retweet(entry):\n",
    "    '''Checks whether a tweet is a retweet'''\n",
    "    if entry != entry: # NaN check\n",
    "        return False\n",
    "    for reference in entry:\n",
    "        if reference[\"type\"] == \"retweeted\":\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_retweet_author(entry):\n",
    "    '''Returns the author ID of the retweeted tweet'''\n",
    "    if entry != entry: # NaN check\n",
    "        return np.nan\n",
    "    for reference in entry:\n",
    "        if reference[\"type\"] == \"retweeted\":\n",
    "            return reference[\"author_id\"]\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2348df86-bb5f-445f-a1e4-b4d1a7e3944d",
   "metadata": {},
   "source": [
    "Apply the functions `check_retweet()` and `get_retweet_author` to the column `referenced_tweets` and create two new columns `retweeted` and `retweet_user_id` containing the relevant information. Again you can use `pandas` [`apply`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53d217d6-6a89-4f08-9beb-847ff6a07805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column \"retweeted\" and set it true if Tweet ist retweeted\n",
    "timelines[\"retweeted\"] = pd.NA # Add a boolean column initialized to pd.NA (empty)\n",
    "\n",
    "for i in range(len(timelines[\"referenced_tweets\"])):\n",
    "    result_retweet_check = check_retweet(timelines.loc[i, \"referenced_tweets\"])\n",
    "    timelines.loc[i, \"retweeted\"] = result_retweet_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19dfabe9-fa17-4eee-80a0-05593f409efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column \"retweet_user_id\" and fill in retweet author ID if Tweet ist retweeted\n",
    "timelines[\"retweet_user_id\"] = \"\"\n",
    "\n",
    "for i in range(len(timelines[\"referenced_tweets\"])):\n",
    "    retweet_author = get_retweet_author(timelines.loc[i, \"referenced_tweets\"])\n",
    "    timelines.loc[i, \"retweet_user_id\"] = retweet_author"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa4746b-96d1-43e8-bac8-7ac92cfb27fa",
   "metadata": {},
   "source": [
    "Filter the tweets in the timelines such that you only retain retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "afadf983-11f3-415c-bc5e-850ec736a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only Tweet with \"retweeted\" == TRUE\n",
    "timelines_with_retweet = timelines.loc[timelines[\"retweeted\"] == True]\n",
    "# timelines_with_retweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3d33b7-25ff-4907-a765-89da6634710c",
   "metadata": {},
   "source": [
    "Now filter the timelines such that the `retweet_user_id` is one of the user IDs in the user list. Use `pandas` [`isin`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isin.html) method for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1c87fd91-cd68-4efa-9230-88cff7dce374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read users data\n",
    "users = pd.read_csv(\"users.csv\", dtype={\"id\":str, \"username\":str, \"party\":str})\n",
    "# print(users.head())\n",
    "\n",
    "# filter timelines witn known users\n",
    "# timelines_filtered = timelines[timelines[\"retweet_user_id\"].isin(users[\"id\"].astype(str))]\n",
    "timelines_filtered = timelines[timelines[\"retweet_user_id\"].isin(users[\"id\"])]\n",
    "\n",
    "#timelines_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0a5575",
   "metadata": {},
   "source": [
    "Now finaly we can start to create the Graph, start by creating an empty graph with `networkx`. See [here](https://networkx.org/documentation/stable/reference/introduction.html#graph-creation) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "81a67723-cb41-42be-992e-1c81ecaaea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94116f1c-7aa7-4be9-87a3-69f9d40f4212",
   "metadata": {},
   "source": [
    "To build the retweet network, we have to fill the empty graph object we just created with nodes and edges. For this purpose, we prepare a list of nodes and their attributes and a list of edges.\n",
    "\n",
    "First, construct a list of vertices (nodes) and node attributes containing the user ids,  screen_names, and the **political party label** of the vertices. Remove all users without a party. Each entry of the list has the following form: \n",
    "\n",
    "`(id, {\"username\":username, \"party\":party})`\n",
    "\n",
    "Use the function [`add_nodes_from`](https://networkx.org/documentation/stable/reference/classes/generated/networkx.Graph.add_nodes_from.html) provided by `networkx` to add the nodes to the graph. \n",
    "\n",
    "Then build a list of edges where every edge is a pair of two users that exchanged at least one retweet with each other (regardless of the direction, remove all duplicate entries). Each entry of the list has the following form:  \n",
    "\n",
    "`(author_id_1, author_id_2)`\n",
    "\n",
    "Use the function [`add_edges_from`](https://networkx.org/documentation/stable/reference/classes/generated/networkx.Graph.add_edges_from.html) provided by `networkx` to add the edges to the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "111c9493-77aa-4332-a08e-e7711ceba23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_image_url</th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "      <th>protected</th>\n",
       "      <th>verified</th>\n",
       "      <th>username</th>\n",
       "      <th>location</th>\n",
       "      <th>url</th>\n",
       "      <th>pinned_tweet_id</th>\n",
       "      <th>name</th>\n",
       "      <th>...</th>\n",
       "      <th>public_metrics.followers_count</th>\n",
       "      <th>public_metrics.following_count</th>\n",
       "      <th>public_metrics.tweet_count</th>\n",
       "      <th>public_metrics.listed_count</th>\n",
       "      <th>entities.url.urls</th>\n",
       "      <th>entities.description.mentions</th>\n",
       "      <th>entities.description.urls</th>\n",
       "      <th>entities.description.hashtags</th>\n",
       "      <th>screenName</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://pbs.twimg.com/profile_images/149375950...</td>\n",
       "      <td>Gemeinderat @al_zuerich. Arbeitet in der @ETHB...</td>\n",
       "      <td>25254764</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>andreaskirstein</td>\n",
       "      <td>Zürich</td>\n",
       "      <td>https://t.co/pbzTpZ2ztz</td>\n",
       "      <td>1.180884e+18</td>\n",
       "      <td>Andreas Kirstein</td>\n",
       "      <td>...</td>\n",
       "      <td>743.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>13640.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>[{'start': 0, 'end': 23, 'url': 'https://t.co/...</td>\n",
       "      <td>[{'start': 12, 'end': 23, 'username': 'al_zuer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>andreaskirstein</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://pbs.twimg.com/profile_images/131178937...</td>\n",
       "      <td>Alt-Gemeinderat Winterthur (Alternative Liste)...</td>\n",
       "      <td>472372843</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>bergerwthur</td>\n",
       "      <td>Winterthur</td>\n",
       "      <td>https://t.co/O4Ttdturoi</td>\n",
       "      <td>1.489913e+18</td>\n",
       "      <td>David B. aus W. 📠 🚱🦬✭</td>\n",
       "      <td>...</td>\n",
       "      <td>526.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>8473.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>[{'start': 0, 'end': 23, 'url': 'https://t.co/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bergerwthur</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://pbs.twimg.com/profile_images/378800000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1948049047</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>maenij</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Martin Jucker</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>maenij</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://pbs.twimg.com/profile_images/143018923...</td>\n",
       "      <td>Seit 2002 Mitglied des Gemeinderats. Leiter Ko...</td>\n",
       "      <td>778497337</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>walterangst</td>\n",
       "      <td>Zürich</td>\n",
       "      <td>https://t.co/c2E4fZgf8f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Walter Angst</td>\n",
       "      <td>...</td>\n",
       "      <td>1042.0</td>\n",
       "      <td>763.0</td>\n",
       "      <td>2052.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>[{'start': 0, 'end': 23, 'url': 'https://t.co/...</td>\n",
       "      <td>[{'start': 63, 'end': 74, 'username': 'MV_Zuer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>walterangst</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://pbs.twimg.com/profile_images/148132495...</td>\n",
       "      <td>Regierungsrätin/Finanzdirektorin</td>\n",
       "      <td>383803341</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>asba_j</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Astrid Bärtschi</td>\n",
       "      <td>...</td>\n",
       "      <td>1484.0</td>\n",
       "      <td>1456.0</td>\n",
       "      <td>5834.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>asba_j</td>\n",
       "      <td>BDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>https://pbs.twimg.com/profile_images/343740423...</td>\n",
       "      <td>SVP-Nationalrätin TG, Geschäftsfrau</td>\n",
       "      <td>1307125520</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>verenaherzog</td>\n",
       "      <td>Frauenfeld</td>\n",
       "      <td>http://t.co/Bc1h6yzSFq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Verena Herzog</td>\n",
       "      <td>...</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>1414.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[{'start': 0, 'end': 22, 'url': 'http://t.co/B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>verenaherzog</td>\n",
       "      <td>SVP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>https://pbs.twimg.com/profile_images/644400819...</td>\n",
       "      <td>Seit 1993 in der Schweiz, verheiratet, 1 Kind,...</td>\n",
       "      <td>1017350089</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>yvette67yvette</td>\n",
       "      <td>Schweiz</td>\n",
       "      <td>http://t.co/IWhzejR7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yvette Estermann</td>\n",
       "      <td>...</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>[{'start': 0, 'end': 20, 'url': 'http://t.co/I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvette67yvette</td>\n",
       "      <td>SVP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>https://pbs.twimg.com/profile_images/153241242...</td>\n",
       "      <td>Give me Liberty, or give me Death!\\n\\nDer Staa...</td>\n",
       "      <td>121068845</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>zac1967</td>\n",
       "      <td>Gossau (ZH), Schweiz</td>\n",
       "      <td>https://t.co/l3p2pWuOnb</td>\n",
       "      <td>1.446920e+18</td>\n",
       "      <td>Claudio Zanetti</td>\n",
       "      <td>...</td>\n",
       "      <td>14881.0</td>\n",
       "      <td>10414.0</td>\n",
       "      <td>156603.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>[{'start': 0, 'end': 23, 'url': 'https://t.co/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zac1967</td>\n",
       "      <td>SVP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>https://pbs.twimg.com/profile_images/132736255...</td>\n",
       "      <td>Doch, das kann man schon machen. Jeder der wen...</td>\n",
       "      <td>606601702</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>chstampfli</td>\n",
       "      <td>Zürich, Schweiz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.367472e+18</td>\n",
       "      <td>Christoph Stampfli</td>\n",
       "      <td>...</td>\n",
       "      <td>1266.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>5474.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'start': 95, 'end': 107, 'username': 'HayekC...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chstampfli</td>\n",
       "      <td>UP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>https://pbs.twimg.com/profile_images/152554589...</td>\n",
       "      <td>Präsident @lp_schweiz. Steuerberater bei @swis...</td>\n",
       "      <td>238913030</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>silvan_amberg</td>\n",
       "      <td>Panama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Silvan Amberg</td>\n",
       "      <td>...</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>10786.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'start': 10, 'end': 21, 'username': 'lp_schw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'start': 138, 'end': 148, 'tag': 'coronasyl'}]</td>\n",
       "      <td>silvan_amberg</td>\n",
       "      <td>UP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>334 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     profile_image_url  \\\n",
       "0    https://pbs.twimg.com/profile_images/149375950...   \n",
       "1    https://pbs.twimg.com/profile_images/131178937...   \n",
       "2    https://pbs.twimg.com/profile_images/378800000...   \n",
       "3    https://pbs.twimg.com/profile_images/143018923...   \n",
       "4    https://pbs.twimg.com/profile_images/148132495...   \n",
       "..                                                 ...   \n",
       "329  https://pbs.twimg.com/profile_images/343740423...   \n",
       "330  https://pbs.twimg.com/profile_images/644400819...   \n",
       "331  https://pbs.twimg.com/profile_images/153241242...   \n",
       "332  https://pbs.twimg.com/profile_images/132736255...   \n",
       "333  https://pbs.twimg.com/profile_images/152554589...   \n",
       "\n",
       "                                           description          id  protected  \\\n",
       "0    Gemeinderat @al_zuerich. Arbeitet in der @ETHB...    25254764      False   \n",
       "1    Alt-Gemeinderat Winterthur (Alternative Liste)...   472372843      False   \n",
       "2                                                  NaN  1948049047      False   \n",
       "3    Seit 2002 Mitglied des Gemeinderats. Leiter Ko...   778497337      False   \n",
       "4                     Regierungsrätin/Finanzdirektorin   383803341      False   \n",
       "..                                                 ...         ...        ...   \n",
       "329                SVP-Nationalrätin TG, Geschäftsfrau  1307125520      False   \n",
       "330  Seit 1993 in der Schweiz, verheiratet, 1 Kind,...  1017350089      False   \n",
       "331  Give me Liberty, or give me Death!\\n\\nDer Staa...   121068845      False   \n",
       "332  Doch, das kann man schon machen. Jeder der wen...   606601702      False   \n",
       "333  Präsident @lp_schweiz. Steuerberater bei @swis...   238913030      False   \n",
       "\n",
       "     verified         username              location                      url  \\\n",
       "0       False  andreaskirstein                Zürich  https://t.co/pbzTpZ2ztz   \n",
       "1       False      bergerwthur            Winterthur  https://t.co/O4Ttdturoi   \n",
       "2       False           maenij                   NaN                      NaN   \n",
       "3       False      walterangst                Zürich  https://t.co/c2E4fZgf8f   \n",
       "4       False           asba_j                   NaN                      NaN   \n",
       "..        ...              ...                   ...                      ...   \n",
       "329     False     verenaherzog            Frauenfeld   http://t.co/Bc1h6yzSFq   \n",
       "330     False   yvette67yvette               Schweiz     http://t.co/IWhzejR7   \n",
       "331     False          zac1967  Gossau (ZH), Schweiz  https://t.co/l3p2pWuOnb   \n",
       "332     False       chstampfli       Zürich, Schweiz                      NaN   \n",
       "333     False    silvan_amberg                Panama                      NaN   \n",
       "\n",
       "     pinned_tweet_id                   name  ...  \\\n",
       "0       1.180884e+18       Andreas Kirstein  ...   \n",
       "1       1.489913e+18  David B. aus W. 📠 🚱🦬✭  ...   \n",
       "2                NaN          Martin Jucker  ...   \n",
       "3                NaN           Walter Angst  ...   \n",
       "4                NaN        Astrid Bärtschi  ...   \n",
       "..               ...                    ...  ...   \n",
       "329              NaN          Verena Herzog  ...   \n",
       "330              NaN       Yvette Estermann  ...   \n",
       "331     1.446920e+18        Claudio Zanetti  ...   \n",
       "332     1.367472e+18     Christoph Stampfli  ...   \n",
       "333              NaN          Silvan Amberg  ...   \n",
       "\n",
       "    public_metrics.followers_count  public_metrics.following_count  \\\n",
       "0                            743.0                           523.0   \n",
       "1                            526.0                           376.0   \n",
       "2                              5.0                            21.0   \n",
       "3                           1042.0                           763.0   \n",
       "4                           1484.0                          1456.0   \n",
       "..                             ...                             ...   \n",
       "329                         1847.0                           908.0   \n",
       "330                         1951.0                           176.0   \n",
       "331                        14881.0                         10414.0   \n",
       "332                         1266.0                           608.0   \n",
       "333                         1805.0                           395.0   \n",
       "\n",
       "     public_metrics.tweet_count  public_metrics.listed_count  \\\n",
       "0                       13640.0                         38.0   \n",
       "1                        8473.0                         17.0   \n",
       "2                           4.0                          0.0   \n",
       "3                        2052.0                         26.0   \n",
       "4                        5834.0                         53.0   \n",
       "..                          ...                          ...   \n",
       "329                      1414.0                        106.0   \n",
       "330                       578.0                        113.0   \n",
       "331                    156603.0                        244.0   \n",
       "332                      5474.0                         29.0   \n",
       "333                     10786.0                         41.0   \n",
       "\n",
       "                                     entities.url.urls  \\\n",
       "0    [{'start': 0, 'end': 23, 'url': 'https://t.co/...   \n",
       "1    [{'start': 0, 'end': 23, 'url': 'https://t.co/...   \n",
       "2                                                  NaN   \n",
       "3    [{'start': 0, 'end': 23, 'url': 'https://t.co/...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "329  [{'start': 0, 'end': 22, 'url': 'http://t.co/B...   \n",
       "330  [{'start': 0, 'end': 20, 'url': 'http://t.co/I...   \n",
       "331  [{'start': 0, 'end': 23, 'url': 'https://t.co/...   \n",
       "332                                                NaN   \n",
       "333                                                NaN   \n",
       "\n",
       "                         entities.description.mentions  \\\n",
       "0    [{'start': 12, 'end': 23, 'username': 'al_zuer...   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3    [{'start': 63, 'end': 74, 'username': 'MV_Zuer...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "329                                                NaN   \n",
       "330                                                NaN   \n",
       "331                                                NaN   \n",
       "332  [{'start': 95, 'end': 107, 'username': 'HayekC...   \n",
       "333  [{'start': 10, 'end': 21, 'username': 'lp_schw...   \n",
       "\n",
       "    entities.description.urls  \\\n",
       "0                         NaN   \n",
       "1                         NaN   \n",
       "2                         NaN   \n",
       "3                         NaN   \n",
       "4                         NaN   \n",
       "..                        ...   \n",
       "329                       NaN   \n",
       "330                       NaN   \n",
       "331                       NaN   \n",
       "332                       NaN   \n",
       "333                       NaN   \n",
       "\n",
       "                        entities.description.hashtags       screenName party  \n",
       "0                                                 NaN  andreaskirstein    AL  \n",
       "1                                                 NaN      bergerwthur    AL  \n",
       "2                                                 NaN           maenij    AL  \n",
       "3                                                 NaN      walterangst    AL  \n",
       "4                                                 NaN           asba_j   BDP  \n",
       "..                                                ...              ...   ...  \n",
       "329                                               NaN     verenaherzog   SVP  \n",
       "330                                               NaN   yvette67yvette   SVP  \n",
       "331                                               NaN          zac1967   SVP  \n",
       "332                                               NaN       chstampfli    UP  \n",
       "333  [{'start': 138, 'end': 148, 'tag': 'coronasyl'}]    silvan_amberg    UP  \n",
       "\n",
       "[334 rows x 21 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_with_party = users.loc[~users[\"party\"].isna() & (users[\"party\"].str.strip() != \"\")]\n",
    "users_with_party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfe5c8e-a0e3-48b9-a750-a39dc9db196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n",
    "nodes = users[[\"id\", \"username\", \"party\"]].dropna(subset=[\"party\"])\n",
    "# Create the node list. Iterate over each row in the nodes dataframe and add the corresponding entry to the list\n",
    "node_list = []\n",
    "...\n",
    "\n",
    "# Add the nodes to the graph\n",
    "G.add_nodes_from(node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b97ed3-09ef-4cce-a2b7-7d176fe99013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n",
    "edges = timelines[[\"author_id\", \"retweet_user_id\"]].drop_duplicates()\n",
    "# Create the edge list. Iterate over each row in the edges dataframe and add the corresponding entry to the list\n",
    "edge_list = []\n",
    "...\n",
    "\n",
    "# Add the edges to the graph\n",
    "G.add_edges_from(edge_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d5b887",
   "metadata": {},
   "source": [
    "Visualize the graph!\n",
    "Use [`draw_networkx`](https://networkx.org/documentation/stable/reference/generated/networkx.drawing.nx_pylab.draw_networkx.html) for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5240f4f3-df85-49b6-8b5c-6907b41c44fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f9f1b8-1b55-43b5-bc37-7389716008d5",
   "metadata": {},
   "source": [
    "# 3. Calculate graph assortativity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083ad210-6321-4625-9732-7da2c639da9d",
   "metadata": {},
   "source": [
    "Use the function [`attribute_assortativity_coefficient`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.assortativity.attribute_assortativity_coefficient.html) of `networkx` to calculate the assortativity with respect to party labels. How high is the value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eed1868-86cc-4752-b88a-b8a15e6cdfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbc8610-98e4-44e3-8774-ccf7d4e54922",
   "metadata": {},
   "source": [
    "To see if the assortativity value fits your expectations, use the function [`draw_networkx`](https://networkx.org/documentation/stable/reference/generated/networkx.drawing.nx_pylab.draw_networkx.html) to plot the network coloring each node according to the political party label of the politician. Does the pattern of colors fit the value of assortativity?\n",
    "\n",
    "Hint 1: use the optional function parameters `nodelist` and `node_color` to pass a list of nodes and a list of corresponding colors to the drawing function.  \n",
    "Hint 2: you can use one of [matplotlibs categorical color maps](https://matplotlib.org/stable/tutorials/colors/colormaps.html) to get a nice series of distinct colors for the parties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce46f1c3-8297-4773-8689-b0d391b9a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!# Your Code goes here!\n",
    "parties = ... # Get the unique parties frome the nodes dataframe\n",
    "cmap = ... # Set the color map\n",
    "colors = ... # Set a color for each unique party\n",
    "color_dict = ... # Create a Color Dictionary where the keys are the parties and the values are the colors\n",
    "\n",
    "node_colors = ... # Create a list where each entry is the color of the party for all parties in the nodes dataframe, do not change the order!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a80be4e-32e1-476e-8e58-69b9e4b96976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the graph\n",
    "fig, ax = plt.subplots()\n",
    "nx.draw_networkx(\n",
    "    G, \n",
    "    nodelist=nodes[\"id\"],\n",
    "    node_color=node_colors,\n",
    "    node_size=10, \n",
    "    with_labels=False,\n",
    "    ax=ax\n",
    ")\n",
    "# let's add a legend! Since draw_network does not do this automatically, we have\n",
    "# to create custom legend elements to add to the plot\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [Line2D([0], [0], marker='o', color=\"w\", label=key,\n",
    "        markerfacecolor=val, markersize=10) for key, val in color_dict.items()]\n",
    "ax.legend(\n",
    "    handles=legend_elements, # customly made legend handles\n",
    "    title=\"parties\", # title of the legend\n",
    "    loc=1, # anchors the legend in the upper right corner\n",
    "    bbox_to_anchor=[1.25, 1, 0, 0] # puts the legend outside the plot\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399248d1-6cdc-46df-a15e-93c54393ae28",
   "metadata": {},
   "source": [
    "# 4. Permutation tests\n",
    "\n",
    "The above result looks assortative, but how can we test if it could have happened at random and not because of party identity? Here were are going to test it with a permutation test.\n",
    "\n",
    "First, let's run a permutation. Perform the same assortativity calculation as above but permuting the party labels of nodes. You can do this very efficiently by using `pandas` [`sample`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) function.\n",
    "\n",
    "Also set the party for each node as node attribute by using [`set_node_attribute`](https://networkx.org/documentation/stable/reference/generated/networkx.classes.function.set_node_attributes.html) (be carefull the parties are now permuted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab7c449-46b0-42a3-be31-0100ac8eb962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349eda64-ccf7-4c28-881b-3021fbafad2c",
   "metadata": {},
   "source": [
    "Is the value much closer to zero?\n",
    "Repeat the calculation with 1000 permutations and plot the histogram of the resulting values. Add a line with the value of the assortativity without permutation. Is it far or close to the permuted values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ccb0e0-12bc-4917-acd2-3d10816498dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6207d899-f786-41d8-bc83-7ae463867797",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(...) # Enter the data for the histogram\n",
    "ax.axvline(...) # Enter the value for the vertical line\n",
    "ax.set_ylabel(\"count\")\n",
    "ax.set_xlabel(\"assortativity\")\n",
    "ax.legend(loc=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ec0ff-8744-4738-a95e-5d787b71822a",
   "metadata": {},
   "source": [
    "To be sure, let's calculate a p-value for the null hypothesis that the assortativity is zero and the alternative hypothesis that it is positive (what we expected):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb8e14e-8cad-4b08-9409-cbbeef8231a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c4e406-dd0a-4c3a-a47b-9c92fa3686d0",
   "metadata": {},
   "source": [
    "After looking at the above results, do you think it is likely that the assortativity we found in the data was produced by chance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d858242-9686-4a29-8b7e-7b50fdbea324",
   "metadata": {},
   "source": [
    "# 5. Community detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91874d7b-7a87-4b78-bb88-02c4fd3e62cc",
   "metadata": {},
   "source": [
    "Let's test if Twitter communities match political affiliations. Remove nodes with degree zero in the network and run the [Louvain community detection algorithm](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.louvain.louvain_communities.html). Visualize the result coloring nodes by community labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fcc80b-d3b7-47fa-94ef-44d05bc86fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n",
    "import networkx.algorithms.community as nx_comm\n",
    "G.remove_nodes_from(list(nx.isolates(G)))\n",
    "communities = ... # Use the louvain algorithm to find communities in the graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4189510-f751-4137-9812-11ea56b07715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some coloring\n",
    "N_communities = len(communities)\n",
    "cmap = ... # Set the color map\n",
    "colors = ... # Set a color for each community\n",
    "color_dict = ... # Create a Color Dictionary where the keys are the communities and the values are the colors\n",
    "\n",
    "node_list = []\n",
    "node_colors = []\n",
    "for i, community in enumerate(communities):\n",
    "    for node in community:\n",
    "        node_list.append(node)\n",
    "        node_colors.append(color_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15327b4-7407-4bfe-8b6c-3e2251d6593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "nx.draw_networkx(\n",
    "    G, \n",
    "    nodelist=node_list,\n",
    "    node_color=node_colors,\n",
    "    node_size=20, \n",
    "    with_labels=False,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# add a legend\n",
    "legend_elements = [Line2D([0], [0], marker='o', color=\"w\", label=key,\n",
    "                          markerfacecolor=val, markersize=10) for key, val in color_dict.items()]\n",
    "ax.legend(\n",
    "    handles=legend_elements,\n",
    "    title=\"communities\",\n",
    "    loc=1, \n",
    "    bbox_to_anchor=[1.25, 1, 0, 0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4ed190-ff56-4210-a8ce-e366fa418ba4",
   "metadata": {},
   "source": [
    "Run the [`modularity`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.quality.modularity.html) function with the above community labels. Is it high enough to think that the network has a community structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e27434-547c-43b3-8c33-350fb3f6cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec818d-32f9-4c6f-be91-f475f3127da7",
   "metadata": {},
   "source": [
    "Repeat but using the party labels instead of the communities detected with Louvain. Is it higher or lower? How far is this modularity from the maximal one found with Louvain?\n",
    "\n",
    "For this iterate over the parties and filter a subset of users that is in the given party and in the graph. Add the ids of these partymembers (do not include any duplicates) and repeat this for all parties.\n",
    "\n",
    "Afterwards you can calculate the modularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71053121-99f9-4754-a69a-b182a0d672c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parties = users[\"party\"].unique()\n",
    "party_communities = []\n",
    "for party in parties:\n",
    "    # filter a subset of users that is in the given party and in the graph\n",
    "    party_members = users[(users[\"party\"] == party) & users[\"id\"].isin(G.nodes)]\n",
    "    party_communities.append(set(party_members[\"id\"].values))\n",
    "\n",
    "# Calculate the modularity of the party communities\n",
    "nx_comm.modularity(G, party_communities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462a4aa1-0b8e-4c01-bb60-aaad998eabac",
   "metadata": {},
   "source": [
    "Finally, to understand which parties are represented in each community, build a data frame for nodes with two columns: one with the party label and another one with the community label. Use the [`groupby()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) function to print a contingency table. Which party or parties compose each community?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936a63bc-a71d-4228-822c-f8777c6654e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n",
    "# create a copy of the user data frame with all users that are also in the graph\n",
    "user_communities = ... # create a copy of the user data frame with all users that are also in the graph\n",
    "user_communities = user_communities.set_index(\"id\") # set the user ID as index\n",
    "user_communities[\"community\"] = -1 # create a new column for the community assignment (initially set to -1)\n",
    "for i, community in enumerate(communities):\n",
    "    # set the community for each user in the community to the community index\n",
    "\n",
    "# Reset the index and sort by party\n",
    "\n",
    "# Look at the created dataframe. Which party or parties are in the same community?\n",
    "# Hint: You can use the .groupby() method to group by a column and then use the .count() method to count the number of entries in each group\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495e2320-8af1-4a72-b50e-66ce0efdbce6",
   "metadata": {},
   "source": [
    "# To learn more\n",
    "* How well can you predict the party of a politician from its neighbors in the network? Here you can use the rule of predicting the party as the majority party among its neighbors and evaluate the accuracy of this approach.\n",
    "* What would be the results if we use the network of replies? Do you expect assortativity and modularity to be higher or lower?\n",
    "* If you retrieved data of follower links, you can repeat the above analysis for undirected following relationships. Do you expect a higher or lower assortativity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6892695e",
   "metadata": {},
   "source": [
    "## Everything down from here is solved and there is no need to do anything, it's just for curious people that want to see another example of a project in our field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ff66a5",
   "metadata": {},
   "source": [
    "## Reddit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ebddb",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "\n",
    "#### Sign up for the Reddit API\n",
    "* In this part of the assignment we will collect data using the Reddit API, and compare the tree structure of political and non-political subreddits.\n",
    "* First, you need to sign up for the Reddit API. For this, follow the steps outlined in [this guide](https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c). You will need to create an app on the following [link](https://old.reddit.com/prefs/apps/).\n",
    "* Next, install the [PRAW package](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html), which provides a nice wrapper for the Reddit API.\n",
    "\n",
    "#### Collect the data\n",
    "* Navigate to the following [link](https://www.reddit.com/best/communities/1/) and select 4 political, and 4 non-political subreddits. Ideally, you would want subreddits with around 100-200 thousand members. You want subreddits with enough engagement, but ones which do not typically have a thousand replies to each submission, since the API has a relatively low rate limit.\n",
    "* Extract the top 20 `hottest` submissions from each of your selected subreddits, ignoring `pinned` submissions.\n",
    "* For each of the submissions, extract all the comments and replies, and store them, so that you don't need to rerun this step later. Make sure to save the `id`, of the post, the id of its `parent` (the post that it replies to) and the name of the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ab76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad5864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from praw.models import Submission, Comment\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388d3f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "political_subs = ['Liberal', 'AskThe_Donald', 'CapitalismVSocialism']\n",
    "non_political_subs = ['learnjava', 'PlayItAgainSam', 'Tokyo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a4acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "REDDIT_ID = 'YrwCRAoZnXy5rx3lLRooiQ'#os.getenv(\"RDT_ID\")\n",
    "REDDIT_SECRET = 'bEBsSPcRnNRatXLz-M2FdU6E1-x4_g' #os.getenv(\"RDT_SECRET\") \n",
    "USER_AGENT = 'homework4' # your user agent         \n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=REDDIT_ID,\n",
    "    client_secret=REDDIT_SECRET,\n",
    "    user_agent=USER_AGENT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55950fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT = 20\n",
    "\n",
    "for sub in tqdm(non_political_subs + political_subs):\n",
    "\n",
    "    results = []\n",
    "    selected_threads = [submission for submission in reddit.subreddit(sub).hot(limit=LIMIT+5) if not (submission.pinned or submission.stickied)]\n",
    "    selected_threads = selected_threads[:LIMIT]\n",
    "    queue = [i for i in selected_threads]\n",
    "\n",
    "    while queue:\n",
    "\n",
    "        post = queue.pop(0)\n",
    "        data = {'name': post.author.name if post.author else 'No author',\n",
    "                 '_id': post.id, 'parent_id': None}\n",
    "\n",
    "        if isinstance(post, Submission):\n",
    "            post.comments.replace_more(limit=0)\n",
    "            responses = list(post.comments)\n",
    "\n",
    "        elif isinstance(post, Comment):\n",
    "            data['parent_id'] = post.parent_id\n",
    "            post.replies.replace_more(limit=0)\n",
    "            responses = list(post.replies)\n",
    "\n",
    "        results.append(data)\n",
    "        queue.extend(responses)\n",
    "\n",
    "    with open(f\"{sub}.json\", \"w\") as f:\n",
    "        json.dump(results, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ff719c",
   "metadata": {},
   "source": [
    "###  Analysis\n",
    "* Create a network/tree for each of the submissions, for this, you may use the [networkx](https://networkx.org/documentation/stable/tutorial.html) package, or create your own classes to store the data.\n",
    "* For each of the trees, calculate the `maximum depth` and `maximum width`. By maximum depth, we mean the number of edges between the root node, and the furthest leaf node (i.e. the reply which is deepest in the comment tree). The maximum width of the tree is the maximum number of comments, replies on one \"level\". On the first \"level\" is the submission itself, on the next one the comments replying directly to the submission, on the third the comments replying to the comments on the first level, and so on.\n",
    "* Also calculate the `number of nodes` for each of the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da521456",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "\n",
    "    def __init__(self, name, _id, parent):\n",
    "        self.name = name\n",
    "        self.id = _id\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "    \n",
    "    def add_child(self, child_name, child_id):\n",
    "        child_node = TreeNode(child_name, child_id, self)\n",
    "        self.children.append(child_node)\n",
    "\n",
    "class Tree:\n",
    "\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "\n",
    "    def add_node(self, parent_id, child_name, child_id):\n",
    "        parent = self.find_node(parent_id)\n",
    "        parent.add_child(child_name, child_id)\n",
    "\n",
    "\n",
    "    def find_node(self, _id):\n",
    "        nodes = [self.root]\n",
    "\n",
    "        _id = _id if '_' not in _id else _id[3:]\n",
    "\n",
    "        while nodes:\n",
    "            node = nodes.pop()\n",
    "\n",
    "            if node.id == _id:\n",
    "                return node\n",
    "\n",
    "            nodes.extend(node.children)\n",
    "\n",
    "    def num_nodes(self):\n",
    "        nodes = [self.root]\n",
    "        count = 0\n",
    "\n",
    "        while nodes:\n",
    "            node = nodes.pop()\n",
    "            count += 1\n",
    "            nodes.extend(node.children)\n",
    "\n",
    "        return count\n",
    "    \n",
    "    def get_leaf_nodes(self):\n",
    "        nodes = [self.root]\n",
    "        leaf_nodes = []\n",
    "\n",
    "        while nodes:\n",
    "            node = nodes.pop()\n",
    "\n",
    "            if not node.children:\n",
    "                leaf_nodes.append(node)\n",
    "            else:\n",
    "                nodes.extend(node.children)\n",
    "\n",
    "        return leaf_nodes\n",
    "    \n",
    "    def max_depth(self):\n",
    "\n",
    "        leaf_nodes = self.get_leaf_nodes()\n",
    "        max_depth = 0\n",
    "\n",
    "        for node in leaf_nodes:\n",
    "\n",
    "            current_node = node\n",
    "            depth = 0\n",
    "\n",
    "            while current_node.parent:\n",
    "                depth += 1\n",
    "                current_node = current_node.parent\n",
    "\n",
    "            if depth > max_depth:\n",
    "                max_depth = depth\n",
    "        \n",
    "\n",
    "        return max_depth\n",
    "    \n",
    "    def max_width(self):\n",
    "\n",
    "        max_width = 1\n",
    "\n",
    "        nodes_on_level = self.root.children\n",
    "\n",
    "        while nodes_on_level:\n",
    "            width = len(nodes_on_level)\n",
    "\n",
    "            if width > max_width:\n",
    "                max_width = width\n",
    "\n",
    "            nodes_on_level = [child for node in nodes_on_level for child in node.children]\n",
    "\n",
    "        return max_width\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a9475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_stats = []\n",
    "\n",
    "for sub in tqdm(non_political_subs + political_subs):\n",
    "\n",
    "\n",
    "    with open(f\"{sub}.json\", \"r\") as f:\n",
    "        results = json.load(f)\n",
    "\n",
    "    root_nodes = [i for i in results if i['parent_id'] is None]\n",
    "\n",
    "    for root_data in root_nodes:\n",
    "        res_copy = [i for i in results]\n",
    "        root = TreeNode(root_data['name'], root_data['_id'], None)\n",
    "        tree = Tree(root)\n",
    "\n",
    "        while res_copy:\n",
    "            node = res_copy.pop(0)\n",
    "\n",
    "            if node['parent_id'] is None:\n",
    "                continue\n",
    "            \n",
    "            parent = tree.find_node(node['parent_id'])\n",
    "\n",
    "            if parent:\n",
    "                parent.add_child(node['name'], node['_id'])\n",
    "\n",
    "        tree_stats.append({'max_width': tree.max_width(), 'max_depth': tree.max_depth(), 'num_nodes': tree.num_nodes(), 'sub': sub})\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a6c97d",
   "metadata": {},
   "source": [
    "### Comparison and interpretation\n",
    "* Compare the mean number of nodes, mean maximum width, and mean maximum depth of political and non-political subreddits. What differences can you notice?\n",
    "* Can you conduct a statistical test to see if the differences are significant?\n",
    "* Create a scatterplot with the max depth of the tree on the x-axis, and the max width of the tree on the y-axis. Color the dots based on their group (political vs. non-political). Interpret your results.\n",
    "* What are the limitations of this analysis? What would you add, or how would you improve it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aa5a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0242d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_df = pd.DataFrame(tree_stats)\n",
    "tree_df['political'] = tree_df['sub'].isin(political_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954079c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_df['num_nodes'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c62f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ttest_ind\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513fed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "political_df = tree_df[tree_df['political'] == True].drop(columns=['political', 'sub']).reset_index(drop=True)\n",
    "non_political_df = tree_df[tree_df['political'] == False].drop(columns=['political', 'sub']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61149f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_dict = {'max_width': [], 'max_depth': [], 'num_nodes': []}\n",
    "\n",
    "num_samples = 10_000\n",
    "\n",
    "for _ in tqdm(range(num_samples)):\n",
    "    tree_df['random_label'] = tree_df['political'].sample(frac=1).values\n",
    "    mean_df = tree_df.groupby('random_label').mean(numeric_only=True)\n",
    "    non_pol_means = mean_df.loc[False]\n",
    "    pol_means = mean_df.loc[True]\n",
    "    mean_diff = pol_means - non_pol_means\n",
    "\n",
    "    for col in means_dict:\n",
    "        tmp_ls = means_dict[col]\n",
    "        tmp_ls.append(mean_diff[col])\n",
    "        means_dict[col] = tmp_ls\n",
    "\n",
    "means_df = pd.DataFrame(means_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8663c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot hist of each column in means_dict\n",
    "true_means = tree_df.groupby('political').mean(numeric_only=True)\n",
    "true_means_diff = true_means.loc[True] - true_means.loc[False]\n",
    "title_dict = {'max_width': 'Tree width', 'max_height': 'Tree height', 'num_nodes': 'Number of nodes'}\n",
    "\n",
    "for col in means_df.columns:\n",
    "    plt.hist(means_df[col], bins=25)\n",
    "    plt.title(col)\n",
    "    # add vertical line for true mean difference\n",
    "    plt.axvline(true_means_diff[col], color='red', linestyle='--', label='true value')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ea9a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_res = ttest_ind(political_df, non_political_df, equal_var=True)\n",
    "\n",
    "print(\"T-Test Results:\")\n",
    "\n",
    "for i, col in enumerate(political_df.columns):\n",
    "    print(f\"{col} -> test statistic: {round(ttest_res.statistic[i], 3)} p-value: {round(ttest_res.pvalue[i], 4)}\")\n",
    "\n",
    "print()\n",
    "print('Permutation Test Results:')\n",
    "for col in political_df.columns:\n",
    "    real_val = true_means_diff[col]\n",
    "    p_val = (sum(abs(val) > abs(real_val) for val in means_df[col].values) + 1) / len(means_df[col].values)\n",
    "    print(f\"{col} -> p-value: {round(p_val, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afade3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot relative frequency curve of max width\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "sns.kdeplot(data=tree_df, x='max_width', hue='political', ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d09a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "46e2835a142a16ae115bce5fddf19f27ce13b17a4ab8ded638c88ab5ce5171d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
