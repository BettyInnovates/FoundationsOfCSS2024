{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Evaluation of Twitter and YouTube Data\n",
    "## Tasks\n",
    "\n",
    "1. Install packages and load evaluation datasets with Google NLP scores\n",
    "2. Run VADER over evaluation texts\n",
    "3. Run BERT over evaluation texts\n",
    "4. Evaluate against sentiment annotations and compare with Google NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install requirements. \n",
    "\n",
    "The following cell contains all the necessary dependencies needed for this task. If you run the cell everything will be installed. \n",
    "\n",
    "* [`vaderSentiment`](https://github.com/cjhutto/vaderSentiment) is a Python package for a Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text.\n",
    "* [`transformers`](https://huggingface.co/) is a Python package for creating and working with transformers. [Here](https://huggingface.co/docs) is the documentation of `transformers`.\n",
    "* [`torch`](https://pytorch.org/) is a Python machine learning framework. We need this here for `transformers` since this package uses internally `torch`. [Here](https://pytorch.org/docs/stable/index.html) is the documentation of `torch`.\n",
    "* [`pandas`](https://pandas.pydata.org/docs/index.html) is a Python package for creating and working with tabular data. [Here](https://pandas.pydata.org/docs/reference/index.html) is the documentation of `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->vaderSentiment) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->vaderSentiment) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\betty\\appdata\\roaming\\python\\python312\\site-packages (from requests->vaderSentiment) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->vaderSentiment) (2024.8.30)\n",
      "Requirement already satisfied: transformers in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.47.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\betty\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: torch in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\betty\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install vaderSentiment\n",
    "! pip install transformers sentencepiece\n",
    "! pip install torch torchvision torchaudio\n",
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to restart the Kernel after installing the dependencies!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import requirements\n",
    "The cell below imports all necessary dependancies. Make sure they are installed (see cell above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load evaluation datasets and Google NLP scores\n",
    "\n",
    "## 1.1 Load datasets\n",
    "First read the Twitter and Youtube Comments CSV files (`Twitter-Sentiment.csv` and `YouTubeComments-Sentiment.csv`) and save them in a pandas Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Twitter data\n",
    "twitter_data = pd.read_csv(\"Twitter-Sentiment.csv\")\n",
    "# print(twitter_data)\n",
    "\n",
    "# Read Youtube data\n",
    "youtube_data = pd.read_csv(\"YouTubeComments-Sentiment.csv\")\n",
    "# print(youtube_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Run VADER over evaluation texts\n",
    "\n",
    "## 2.1 Run VADER over the first tweet\n",
    "\n",
    "In this task you should use VADER for sentiment analysis. For this we use the `vaderSentiment` package. You first have to intatiate a new `SentimentIntensityAnalyzer` and use the `polarity_scores` method of it for the analysis. Apply this for the first tweet. Is it a good classification?\n",
    "\n",
    "[Here](https://github.com/cjhutto/vaderSentiment) under 'Code Examples' you can find some example code how to use this package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Tweet: ?RT @justinbiebcr: The bigger the better....if you know what I mean ;)\n",
      "\n",
      "Classification first Tweet: {'neg': 0.0, 'neu': 0.853, 'pos': 0.147, 'compound': 0.2263}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Intatiate a new SentimentIntensityAnalyzer\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Cassify first tweet and print\n",
    "first_tweet = twitter_data[\"text\"][0]\n",
    "first_tweet_classification = vader.polarity_scores(first_tweet)\n",
    "\n",
    "print(f\"First Tweet: {first_tweet}\\n\")\n",
    "print(f\"Classification first Tweet: {first_tweet_classification}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analyzed tweet is predominantly neutral (neu: 0.853) but leans slightly positive overall (compound: 0.2263 and pos: 0.147).\n",
    "There’s no detectable negativity (neg: 0.0), so the tone of the tweet is likely neutral to mildly positive.\n",
    "\n",
    "The classification is reasonable but not perfect. VADER captures the neutral structure and mild positivity but misses the playful, suggestive tone implied by the wink emoji and double entendre. It also overlooks the broader context and cultural nuances, such as the implied humor in \"if you know what I mean.\" While suitable for general analysis, it lacks the sophistication to interpret subtle humor, innuendo, or contextual cues in tweets like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Run VADER over each text\n",
    "\n",
    "Now use VADER for all the text data of the Twitter and the Youtube dataframe. Create a new column in the dataframes called `VADER_compound` where you save the `compound` result (look at the output dictonary of the `polarity_scores` method).\n",
    "\n",
    "*Important: Make sure `compound` is a float*\n",
    "\n",
    "If this runs slow on your computer you can use the precomputed values in the provided CSV files which are present in the column `VADER_compund_precomputed` for further tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using VADER for sentiment analysis of twitter data\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "twitter_data[\"VADER_compound\"] = 0.0\n",
    "\n",
    "#for i in range(10):\n",
    "for i in range(len(twitter_data[\"text\"])):\n",
    "    # use polarity_scores method to get the sentiment scores\n",
    "    sentiment_dict = vader.polarity_scores(twitter_data[\"text\"][i])\n",
    "    # Save the compound result as float in the dataset. \n",
    "    # Notice: .loc is way slower here.... but worked for us ;)\n",
    "    twitter_data.loc[i, \"VADER_compound\"] = sentiment_dict[\"compound\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using VADER for sentiment analysis of YouTube data\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "youtube_data[\"VADER_compound\"] = 0.0\n",
    "\n",
    "#for i in range(10):\n",
    "for i in range(len(youtube_data[\"text\"])):\n",
    "    # use polarity_scores method to get the sentiment scores\n",
    "    sentiment_dict = vader.polarity_scores(youtube_data[\"text\"][i])\n",
    "    # Save the compound result as float in the dataset. \n",
    "    # Notice: .loc is way slower here.... but worked for us ;)\n",
    "    youtube_data.loc[i, \"VADER_compound\"] = sentiment_dict[\"compound\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 VADER as a classifier\n",
    "\n",
    "To get the three Classes `Positive`, `Negative` and `Neutral` we use the compound score with the following thresholds:\n",
    "\n",
    "* `compound > 0.5`: `\"Positive\"`\n",
    "* `compound < -0.5`: `\"Negative\"`\n",
    "* `else`: `\"Neutral\"`\n",
    "\n",
    "Create a new column called `VADER_class` which contains the three computed classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column for computed classes\n",
    "twitter_data[\"VADER_class\"] = \"Neutral\"\n",
    "youtube_data[\"VADER_class\"] = \"Neutral\"\n",
    "\n",
    "# Classify Twitter Data\n",
    "twitter_data.loc[twitter_data[\"VADER_compound\"] > 0.5, \"VADER_class\"] = \"Positive\"\n",
    "twitter_data.loc[twitter_data[\"VADER_compound\"] < 0.5, \"VADER_class\"] = \"Negative\"\n",
    "\n",
    "# Classify YouTube Data\n",
    "youtube_data.loc[youtube_data[\"VADER_compound\"] > 0.5, \"VADER_class\"] = \"Positive\"\n",
    "youtube_data.loc[youtube_data[\"VADER_compound\"] < 0.5, \"VADER_class\"] = \"Negative\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Use a BERT based model for sentiment analysis\n",
    "\n",
    "## 3.1 BERT\n",
    "BERT (Bidirectional Encoder Representation from Transformers) is a machine learning technique for natural language processing. There are already pretrained models available in the `transformers` package. You can look [here](https://huggingface.co/models?sort=downloads&search=sentiment) and choose a model for the next tasks. (We suggest [this](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest) (`\"cardiffnlp/twitter-roberta-base-sentiment-latest\"`) model, but you can use any available, just make sure it is suitable for sentiment analysis).\n",
    "\n",
    "First create a `pipeline` where you set your model by the `model` keyword argument. You can then use this method to pass text which should be classified. [Here](https://huggingface.co/blog/sentiment-analysis-python#2-how-to-use-pre-trained-sentiment-analysis-models-with-python) is a tutorial how to use this.\n",
    "\n",
    "As before save the classes in a new row 'BERT_class'. The call to your pipeline returns a dictionary where there is a key `label` which contains already the `Positive`, `Negative` or `Neutral` class (Be aware that this is based on the model you choose, sometimes these classes are named differently so you have to rename them by hand, this is not the case if you use the suggested model).\n",
    "\n",
    "Based on you computer this may take some time, if it is too slow for you, you can again use the precomputed classes `'BERT_class_precomputed'` in the CSV Files for further tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using BERT-Base-Uncased model for sentiment analysis\n",
    "#sentiment_pipeline = pipeline(model=f\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "# Create new column for computed BERT classes\n",
    "#twitter_data[\"BERT_class\"] = \"Neutral\"\n",
    "#youtube_data[\"BERT_class\"] = \"Neutral\"\n",
    "\n",
    "# twitter_data\n",
    "\n",
    "# column_to_classify = \"BERT_class_precomputed\"\n",
    "# column_to_classify = \"BERT_class\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluate against sentiment annotations and compare with Google NLP\n",
    "\n",
    "## 4.1 Convert GoogleNLP scores to classes\n",
    "\n",
    "As with VADER and BERT, compute classes from the GoogleNLP score, which is given in the column `googleScore`. For this use following thresholds:\n",
    "\n",
    "* `googleScore > 0.3`: `\"Positive\"`\n",
    "* `googleScore < -0.3`: `\"Negativ\"`\n",
    "* `else`: `\"Neutral\"`\n",
    "\n",
    "Save the classes in a new column named `GoogleNLP_class`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>googleScore</th>\n",
       "      <th>VADER_compound_precomputed</th>\n",
       "      <th>BERT_class_precomputed</th>\n",
       "      <th>VADER_compound</th>\n",
       "      <th>VADER_class</th>\n",
       "      <th>GoogleNLP_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>?RT @justinbiebcr: The bigger the better....if...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Listening to the \"New Age\" station on @Slacker...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>I favorited a YouTube video -- Drake and Josh ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>i didnt mean knee high I ment in lengt it goes...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8632</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.8632</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>I wana see the vid Kyan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>So far, i'm seeing the opposite of what you're...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>RT @Nescreation I'm Yours w/ hearts Ladies Cam...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @JoseCarol: If you fall, GET UP!, if you're...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6531</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6531</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>@MakikiGirl I'm giving my 2 Japanese Chins a b...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>T-Mobile USA Says They Ditched Yahoo For Googl...</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.2263</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>-0.2263</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4209 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                               text  \\\n",
       "0     Positive  ?RT @justinbiebcr: The bigger the better....if...   \n",
       "1     Positive  Listening to the \"New Age\" station on @Slacker...   \n",
       "2      Neutral  I favorited a YouTube video -- Drake and Josh ...   \n",
       "3     Positive  i didnt mean knee high I ment in lengt it goes...   \n",
       "4      Neutral                            I wana see the vid Kyan   \n",
       "...        ...                                                ...   \n",
       "4204   Neutral  So far, i'm seeing the opposite of what you're...   \n",
       "4205   Neutral  RT @Nescreation I'm Yours w/ hearts Ladies Cam...   \n",
       "4206  Positive  RT @JoseCarol: If you fall, GET UP!, if you're...   \n",
       "4207   Neutral  @MakikiGirl I'm giving my 2 Japanese Chins a b...   \n",
       "4208   Neutral  T-Mobile USA Says They Ditched Yahoo For Googl...   \n",
       "\n",
       "      googleScore  VADER_compound_precomputed BERT_class_precomputed  \\\n",
       "0             0.3                      0.2263               Positive   \n",
       "1             0.2                      0.0000                Neutral   \n",
       "2             0.0                      0.4019               Positive   \n",
       "3             0.8                      0.8632               Positive   \n",
       "4             0.0                      0.0000                Neutral   \n",
       "...           ...                         ...                    ...   \n",
       "4204          0.4                      0.0000               Negative   \n",
       "4205          0.3                      0.6486                Neutral   \n",
       "4206          0.3                      0.6531               Positive   \n",
       "4207         -0.1                     -0.2023               Negative   \n",
       "4208         -0.3                     -0.2263                Neutral   \n",
       "\n",
       "      VADER_compound VADER_class GoogleNLP_class  \n",
       "0             0.2263    Negative         Neutral  \n",
       "1             0.0000    Negative         Neutral  \n",
       "2             0.4019    Negative         Neutral  \n",
       "3             0.8632    Positive        Positive  \n",
       "4             0.0000    Negative         Neutral  \n",
       "...              ...         ...             ...  \n",
       "4204          0.0000    Negative        Positive  \n",
       "4205          0.6486    Positive         Neutral  \n",
       "4206          0.6531    Positive         Neutral  \n",
       "4207         -0.2023    Negative         Neutral  \n",
       "4208         -0.2263    Negative         Neutral  \n",
       "\n",
       "[4209 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new column for Google NLP classes\n",
    "twitter_data[\"GoogleNLP_class\"] = \"Neutral\"\n",
    "youtube_data[\"GoogleNLP_class\"] = \"Neutral\"\n",
    "\n",
    "# Classify Twitter Data\n",
    "twitter_data.loc[twitter_data[\"googleScore\"] > 0.3, \"GoogleNLP_class\"] = \"Positive\"\n",
    "twitter_data.loc[twitter_data[\"googleScore\"] < -0.3, \"GoogleNLP_class\"] = \"Negative\"\n",
    "\n",
    "# Classify YouTube Data\n",
    "youtube_data.loc[youtube_data[\"googleScore\"] > 0.3, \"GoogleNLP_class\"] = \"Positive\"\n",
    "youtube_data.loc[youtube_data[\"googleScore\"] < -0.3, \"GoogleNLP_class\"] = \"Negative\"\n",
    "\n",
    "youtube_data\n",
    "twitter_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Evaluate on Twitter\n",
    "\n",
    "First, let's calculate the accuracy for all three classifiers on the Twitter and Youtube data, print the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Formula\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Samples}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Twitter Samples: 4209\n",
      "Total Number of YouTube Samples: 3293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get number of Samples\n",
    "number_twitter_samples = len(twitter_data.index)\n",
    "number_youtube_samples = len(youtube_data.index)\n",
    "print(f\"Total Number of Twitter Samples: {number_twitter_samples}\")\n",
    "print(f\"Total Number of YouTube Samples: {number_youtube_samples}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose colum to evaluate of BERT calssifications\n",
    "column_to_validate = \"BERT_class_precomputed\"\n",
    "# column_to_validate = \"BERT_class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Correct Predictions for Twitter by VADER: 758\n",
      "Number of Correct Predictions for Twitter by BERT: 2672\n",
      "Number of Correct Predictions for Twitter by Google NLP: 2825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get number of Correct Predictions for Twitter Samples\n",
    "correct_predictiions_VADER_on_twitter_data = twitter_data[twitter_data[\"VADER_class\"]==twitter_data[\"label\"]].shape[0]\n",
    "print(f\"Number of Correct Predictions for Twitter by VADER: {correct_predictiions_VADER_on_twitter_data}\")\n",
    "correct_predictiions_BERT_on_twitter_data = twitter_data[twitter_data[column_to_validate]==twitter_data[\"label\"]].shape[0]\n",
    "print(f\"Number of Correct Predictions for Twitter by BERT: {correct_predictiions_BERT_on_twitter_data}\")\n",
    "correct_predictiions_GoogleNLP_on_twitter_data = twitter_data[twitter_data[\"GoogleNLP_class\"]==twitter_data[\"label\"]].shape[0]\n",
    "print(f\"Number of Correct Predictions for Twitter by Google NLP: {correct_predictiions_GoogleNLP_on_twitter_data}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Correct Predictions for YouTube by VADER: 1374\n",
      "Number of Correct Predictions for YouTube by BERT: 2448\n",
      "Number of Correct Predictions for YouTube by Google NLP: 2172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get number of Correct Predictions for YouTube Samples\n",
    "correct_predictiions_VADER_on_youtube_data = youtube_data[youtube_data[\"VADER_class\"]==youtube_data[\"label\"]].shape[0]\n",
    "print(f\"Number of Correct Predictions for YouTube by VADER: {correct_predictiions_VADER_on_youtube_data}\")\n",
    "correct_predictiions_BERT_on_youtube_data = youtube_data[youtube_data[column_to_validate]==youtube_data[\"label\"]].shape[0]\n",
    "print(f\"Number of Correct Predictions for YouTube by BERT: {correct_predictiions_BERT_on_youtube_data}\")\n",
    "correct_predictiions_GoogleNLP_on_youtube_data = youtube_data[youtube_data[\"GoogleNLP_class\"]==youtube_data[\"label\"]].shape[0]\n",
    "print(f\"Number of Correct Predictions for YouTube by Google NLP: {correct_predictiions_GoogleNLP_on_youtube_data}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of VADER on Twitter Samples: 0.18009028272748873 meaning 18.01%\n",
      "Accuracy of BERT on Twitter Samples: 0.6348301259206462 meaning 63.48%\n",
      "Accuracy of Google NLP on Twitter Samples: 0.6711808030411024 meaning 67.12%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate Accuracy of Pedictions on Twitter Samples\n",
    "accuracy_VADER_on_twitter = correct_predictiions_VADER_on_twitter_data / number_twitter_samples\n",
    "accuracy_BERT_on_twitter = correct_predictiions_BERT_on_twitter_data / number_twitter_samples\n",
    "accuracy_GoogleNLP_on_twitter = correct_predictiions_GoogleNLP_on_twitter_data / number_twitter_samples\n",
    "\n",
    "print(f\"Accuracy of VADER on Twitter Samples: {accuracy_VADER_on_twitter} meaning {accuracy_VADER_on_twitter*100:.2f}%\")\n",
    "print(f\"Accuracy of BERT on Twitter Samples: {accuracy_BERT_on_twitter} meaning {accuracy_BERT_on_twitter*100:.2f}%\")\n",
    "print(f\"Accuracy of Google NLP on Twitter Samples: {accuracy_GoogleNLP_on_twitter} meaning {accuracy_GoogleNLP_on_twitter*100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of VADER on YouTube Samples: 0.41724870938354086 meaning 41.72%\n",
      "Accuracy of BERT on YouTube Samples: 0.7433950804737322 meaning 74.34%\n",
      "Accuracy of Google NLP on YouTube Samples: 0.6595809292438506 meaning 65.96%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate Accuracy of Pedictions on YouTube Samples\n",
    "accuracy_VADER_on_youtube = correct_predictiions_VADER_on_youtube_data / number_youtube_samples\n",
    "accuracy_BERT_on_youtube = correct_predictiions_BERT_on_youtube_data / number_youtube_samples\n",
    "accuracy_GoogleNLP_on_youtube = correct_predictiions_GoogleNLP_on_youtube_data / number_youtube_samples\n",
    "\n",
    "print(f\"Accuracy of VADER on YouTube Samples: {accuracy_VADER_on_youtube} meaning {accuracy_VADER_on_youtube*100:.2f}%\")\n",
    "print(f\"Accuracy of BERT on YouTube Samples: {accuracy_BERT_on_youtube} meaning {accuracy_BERT_on_youtube*100:.2f}%\")\n",
    "print(f\"Accuracy of Google NLP on YouTube Samples: {accuracy_GoogleNLP_on_youtube} meaning {accuracy_GoogleNLP_on_youtube*100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next calculate the precision of the `\"Positive\"` class for the Twitter and Youtube data.\n",
    "This is calculated as follows:\n",
    "$\n",
    "\\begin{align}\n",
    "    precision = \\frac{TP}{TP + FP}\n",
    "\\end{align}\n",
    "$\n",
    "*Note: Here the Positive samples are the one with the the class `\"Positive\"`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Positives (TP) for the \"Positive\" Class\n",
    "\n",
    "To calculate the **True Positives (TP)** for the `\"Positive\"` class, we need to identify the cases where:\n",
    "- The **actual class** is `\"Positive\"`, and\n",
    "- The **predicted class** is also `\"Positive\"` (lable fits classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive VADER on Twitter Samples: 427\n",
      "True Positive BERT on Twitter Samples: 537\n",
      "True Positive Google NLP on Twitter Samples: 328\n",
      "\n",
      "True Positive VADER on YouTube Samples: 912\n",
      "True Positive BERT on YouTube Samples: 1202\n",
      "True Positive Google NLP on YouTube Samples: 914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate True Positive\n",
    "TP_VADER_on_twitter_data = twitter_data[(twitter_data[\"VADER_class\"] == twitter_data[\"label\"]) & (twitter_data[\"VADER_class\"] == \"Positive\")].shape[0]\n",
    "TP_BERT_on_twitter_data = twitter_data[(twitter_data[column_to_validate] == twitter_data[\"label\"]) & (twitter_data[column_to_validate] == \"Positive\")].shape[0]\n",
    "TP_GoogleNLP_on_twitter_data = twitter_data[(twitter_data[\"GoogleNLP_class\"] == twitter_data[\"label\"]) & (twitter_data[\"GoogleNLP_class\"] == \"Positive\")].shape[0]\n",
    "\n",
    "print(f\"True Positive VADER on Twitter Samples: {TP_VADER_on_twitter_data}\")\n",
    "print(f\"True Positive BERT on Twitter Samples: {TP_BERT_on_twitter_data}\")\n",
    "print(f\"True Positive Google NLP on Twitter Samples: {TP_GoogleNLP_on_twitter_data}\\n\")\n",
    "\n",
    "TP_VADER_on_youtube_data = youtube_data[(youtube_data[\"VADER_class\"] == youtube_data[\"label\"]) & (youtube_data[\"VADER_class\"] == \"Positive\")].shape[0]\n",
    "TP_BERT_on_youtube_data = youtube_data[(youtube_data[column_to_validate] == youtube_data[\"label\"]) & (youtube_data[column_to_validate] == \"Positive\")].shape[0]\n",
    "TP_GoogleNLP_on_youtube_data = youtube_data[(youtube_data[\"GoogleNLP_class\"] == youtube_data[\"label\"]) & (youtube_data[\"GoogleNLP_class\"] == \"Positive\")].shape[0]\n",
    "\n",
    "print(f\"True Positive VADER on YouTube Samples: {TP_VADER_on_youtube_data}\")\n",
    "print(f\"True Positive BERT on YouTube Samples: {TP_BERT_on_youtube_data}\")\n",
    "print(f\"True Positive Google NLP on YouTube Samples: {TP_GoogleNLP_on_youtube_data}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positives (FP) for the \"Positive\" Class\n",
    "\n",
    "To calculate the **False Positives (FP)** for the `\"Positive\"` class, we need to identify the cases where:\n",
    "- The **predicted class** is `\"Positive\"` but\n",
    "- The **actual class** is **not** `\"Positive\"` (lable does not fit classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive VADER on Twitter Samples: 774\n",
      "False Positive BERT on Twitter Samples: 964\n",
      "False Positive Google NLP on Twitter Samples: 651\n",
      "\n",
      "False Positive VADER on YouTube Samples: 354\n",
      "False Positive BERT on YouTube Samples: 372\n",
      "False Positive Google NLP on YouTube Samples: 270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate False Positive\n",
    "FP_VADER_on_twitter_data = twitter_data[(twitter_data[\"VADER_class\"] != twitter_data[\"label\"]) & (twitter_data[\"VADER_class\"] == \"Positive\")].shape[0]\n",
    "FP_BERT_on_twitter_data = twitter_data[(twitter_data[column_to_validate] != twitter_data[\"label\"]) & (twitter_data[column_to_validate] == \"Positive\")].shape[0]\n",
    "FP_GoogleNLP_on_twitter_data = twitter_data[(twitter_data[\"GoogleNLP_class\"] != twitter_data[\"label\"]) & (twitter_data[\"GoogleNLP_class\"] == \"Positive\")].shape[0]\n",
    "\n",
    "print(f\"False Positive VADER on Twitter Samples: {FP_VADER_on_twitter_data}\")\n",
    "print(f\"False Positive BERT on Twitter Samples: {FP_BERT_on_twitter_data}\")\n",
    "print(f\"False Positive Google NLP on Twitter Samples: {FP_GoogleNLP_on_twitter_data}\\n\")\n",
    "\n",
    "FP_VADER_on_youtube_data = youtube_data[(youtube_data[\"VADER_class\"] != youtube_data[\"label\"]) & (youtube_data[\"VADER_class\"] == \"Positive\")].shape[0]\n",
    "FP_BERT_on_youtube_data = youtube_data[(youtube_data[column_to_validate] != youtube_data[\"label\"]) & (youtube_data[column_to_validate] == \"Positive\")].shape[0]\n",
    "FP_GoogleNLP_on_youtube_data = youtube_data[(youtube_data[\"GoogleNLP_class\"] != youtube_data[\"label\"]) & (youtube_data[\"GoogleNLP_class\"] == \"Positive\")].shape[0]\n",
    "\n",
    "print(f\"False Positive VADER on YouTube Samples: {FP_VADER_on_youtube_data}\")\n",
    "print(f\"False Positive BERT on YouTube Samples: {FP_BERT_on_youtube_data}\")\n",
    "print(f\"False Positive Google NLP on YouTube Samples: {FP_GoogleNLP_on_youtube_data}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive VADER on Twitter Samples: 1201\n",
      "Positive BERT on Twitter Samples: 1501\n",
      "Positive Google NLP on Twitter Samples: 979\n",
      "\n",
      "Positive VADER on YouTube Samples: 1266\n",
      "Positive BERT on YouTube Samples: 1574\n",
      "Positive Google NLP on YouTube Samples: 1184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the total number of positive predictions – just for verification\n",
    "print(f\"Positive VADER on Twitter Samples: {twitter_data[twitter_data[\"VADER_class\"] == \"Positive\"].shape[0]}\")\n",
    "print(f\"Positive BERT on Twitter Samples: {twitter_data[twitter_data[\"BERT_class_precomputed\"] == \"Positive\"].shape[0]}\")\n",
    "print(f\"Positive Google NLP on Twitter Samples: {twitter_data[twitter_data[\"GoogleNLP_class\"] == \"Positive\"].shape[0]}\\n\")\n",
    "\n",
    "print(f\"Positive VADER on YouTube Samples: {youtube_data[youtube_data[\"VADER_class\"] == \"Positive\"].shape[0]}\")\n",
    "print(f\"Positive BERT on YouTube Samples: {youtube_data[youtube_data[\"BERT_class_precomputed\"] == \"Positive\"].shape[0]}\")\n",
    "print(f\"Positive Google NLP on YouTube Samples: {youtube_data[youtube_data[\"GoogleNLP_class\"] == \"Positive\"].shape[0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating\n",
    "$\n",
    "\\begin{align}\n",
    "    precision = \\frac{TP}{TP + FP}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision VADER on Twitter Samples: 0.3555370524562864 meaning 35.55%\n",
      "Precision BERT on Twitter Samples: 0.357761492338441 meaning 35.78%\n",
      "Precision Google NLP on Twitter Samples: 0.3350357507660878 meaning 33.50%\n",
      "\n",
      "Precision VADER on YouTube Samples: 0.7203791469194313 meaning 72.04%\n",
      "Precision BERT on YouTube Samples: 0.7636594663278272 meaning 76.37%\n",
      "Precision Google NLP on YouTube Samples: 0.7719594594594594 meaning 77.20%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate Precision on Twitter Data\n",
    "precision_VADER_on_twitter_data = TP_VADER_on_twitter_data / (TP_VADER_on_twitter_data + FP_VADER_on_twitter_data)\n",
    "precision_BERT_on_twitter_data = TP_BERT_on_twitter_data / (TP_BERT_on_twitter_data + FP_BERT_on_twitter_data)\n",
    "precision_GoogleNLP_on_twitter_data = TP_GoogleNLP_on_twitter_data / (TP_GoogleNLP_on_twitter_data + FP_GoogleNLP_on_twitter_data)\n",
    "\n",
    "print(f\"Precision VADER on Twitter Samples: {precision_VADER_on_twitter_data} meaning {precision_VADER_on_twitter_data*100:.2f}%\")\n",
    "print(f\"Precision BERT on Twitter Samples: {precision_BERT_on_twitter_data} meaning {precision_BERT_on_twitter_data*100:.2f}%\")\n",
    "print(f\"Precision Google NLP on Twitter Samples: {precision_GoogleNLP_on_twitter_data} meaning {precision_GoogleNLP_on_twitter_data*100:.2f}%\\n\") \t \n",
    "\n",
    "# Calculate Precision on YouTube Data\n",
    "precision_VADER_on_youtube_data = TP_VADER_on_youtube_data / (TP_VADER_on_youtube_data + FP_VADER_on_youtube_data)\n",
    "precision_BERT_on_youtube_data = TP_BERT_on_youtube_data / (TP_BERT_on_youtube_data + FP_BERT_on_youtube_data)\n",
    "precision_GoogleNLP_on_youtube_data = TP_GoogleNLP_on_youtube_data / (TP_GoogleNLP_on_youtube_data + FP_GoogleNLP_on_youtube_data)\n",
    "\n",
    "print(f\"Precision VADER on YouTube Samples: {precision_VADER_on_youtube_data} meaning {precision_VADER_on_youtube_data*100:.2f}%\")\n",
    "print(f\"Precision BERT on YouTube Samples: {precision_BERT_on_youtube_data} meaning {precision_BERT_on_youtube_data*100:.2f}%\")\n",
    "print(f\"Precision Google NLP on YouTube Samples: {precision_GoogleNLP_on_youtube_data} meaning {precision_GoogleNLP_on_youtube_data*100:.2f}%\\n\") \t "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the recall score. This is done by:\n",
    "$\n",
    "\\begin{align}\n",
    "    recall = \\frac{TP}{TP + FN}\n",
    "\\end{align}\n",
    "$\n",
    "*Note: Here the Positive samples are the one with the the class `\"Positive\"`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Negatives (FN) for the \"Positive\" Class\n",
    "\n",
    "To calculate the **False Negatives (FN)** for the `\"Positive\"` class, we need to identify the cases where:\n",
    "- The **actual class** is `\"Positive\"`, but\n",
    "- The **predicted class** is **not** `\"Positive\"` (i.e., it is `\"Negative\"` or `\"Neutral\"`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Negative (class \"Positive\") VADER on Twitter Samples: 160\n",
      "False Negative (class \"Positive\") BERT on Twitter Samples: 50\n",
      "False Negative (class \"Positive\") Google NLP on Twitter Samples: 259\n",
      "\n",
      "False Negative (class \"Positive\") VADER on YouTube Samples: 1565\n",
      "False Negative (class \"Positive\") BERT on YouTube Samples: 473\n",
      "False Negative (class \"Positive\") Google NLP on YouTube Samples: 851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate False Negative for class \"Positive\"\n",
    "FN_VADER_on_twitter_data = twitter_data[(twitter_data[\"label\"] == \"Positive\" ) & (twitter_data[\"VADER_class\"] != \"Positive\")].shape[0]\n",
    "FN_BERT_on_twitter_data = twitter_data[(twitter_data[\"label\"] == \"Positive\") & (twitter_data[column_to_validate] != \"Positive\")].shape[0]\n",
    "FN_GoogleNLP_on_twitter_data = twitter_data[(twitter_data[\"label\"] == \"Positive\") & (twitter_data[\"GoogleNLP_class\"] != \"Positive\")].shape[0]\n",
    "\n",
    "print(f\"False Negative (class \\\"Positive\\\") VADER on Twitter Samples: {FN_VADER_on_twitter_data}\")\n",
    "print(f\"False Negative (class \\\"Positive\\\") BERT on Twitter Samples: {FN_BERT_on_twitter_data}\")\n",
    "print(f\"False Negative (class \\\"Positive\\\") Google NLP on Twitter Samples: {FN_GoogleNLP_on_twitter_data}\\n\")\n",
    "\n",
    "FN_VADER_on_youtube_data = youtube_data[(youtube_data[\"label\"] == \"Positive\") & (youtube_data[\"VADER_class\"] != \"Positive\")].shape[0]\n",
    "FN_BERT_on_youtube_data = youtube_data[(youtube_data[\"label\"] == \"Positive\") & (youtube_data[column_to_validate] != \"Positive\")].shape[0]\n",
    "FN_GoogleNLP_on_youtube_data = youtube_data[(youtube_data[\"label\"] == \"Positive\") & (youtube_data[\"GoogleNLP_class\"] != \"Positive\")].shape[0]\n",
    "\n",
    "print(f\"False Negative (class \\\"Positive\\\") VADER on YouTube Samples: {TP_VADER_on_youtube_data}\")\n",
    "print(f\"False Negative (class \\\"Positive\\\") BERT on YouTube Samples: {TP_BERT_on_youtube_data}\")\n",
    "print(f\"False Negative (class \\\"Positive\\\") Google NLP on YouTube Samples: {TP_GoogleNLP_on_youtube_data}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate \n",
    "$\n",
    "\\begin{align}\n",
    "    recall = \\frac{TP}{TP + FN}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall (class \"Positive\") VADER on Twitter Samples: 0.727427597955707 meaning 72.74%\n",
      "Recall (class \"Positive\") BERT on Twitter Samples: 0.9148211243611585 meaning 91.48%\n",
      "Recall (class \"Positive\") Google NLP on Twitter Samples: 0.5587734241908007 meaning 55.88%\n",
      "\n",
      "Recall (class \"Positive\") VADER on YouTube Samples: 0.7960325534079349 meaning 79.60%\n",
      "Recall (class \"Positive\") BERT on YouTube Samples: 0.809931506849315 meaning 80.99%\n",
      "Recall (class \"Positive\") Google NLP on YouTube Samples: 0.6808 meaning 68.08%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate recall for class \"Positive\"\n",
    "recall_VADER_on_twitter_data = TP_VADER_on_twitter_data / (TP_VADER_on_twitter_data + FN_VADER_on_twitter_data)\n",
    "recall_BERT_on_twitter_data = TP_BERT_on_twitter_data / (TP_BERT_on_twitter_data + FN_BERT_on_twitter_data)\n",
    "recall_GoogleNLP_on_twitter_data = TP_GoogleNLP_on_twitter_data / (TP_GoogleNLP_on_twitter_data + FN_GoogleNLP_on_twitter_data)\n",
    "\n",
    "print(f\"Recall (class \\\"Positive\\\") VADER on Twitter Samples: {recall_VADER_on_twitter_data} meaning {recall_VADER_on_twitter_data*100:.2f}%\")\n",
    "print(f\"Recall (class \\\"Positive\\\") BERT on Twitter Samples: {recall_BERT_on_twitter_data} meaning {recall_BERT_on_twitter_data*100:.2f}%\")\n",
    "print(f\"Recall (class \\\"Positive\\\") Google NLP on Twitter Samples: {recall_GoogleNLP_on_twitter_data} meaning {recall_GoogleNLP_on_twitter_data*100:.2f}%\\n\") \n",
    "\n",
    "recall_VADER_on_youtube_data = TP_VADER_on_youtube_data / (TP_VADER_on_youtube_data + FN_VADER_on_youtube_data)\n",
    "recall_BERT_on_youtube_data = TP_BERT_on_youtube_data / (TP_BERT_on_youtube_data + FN_BERT_on_youtube_data)\n",
    "recall_GoogleNLP_on_youtube_data = TP_GoogleNLP_on_youtube_data / (TP_GoogleNLP_on_youtube_data + FN_GoogleNLP_on_youtube_data)\n",
    "\n",
    "print(f\"Recall (class \\\"Positive\\\") VADER on YouTube Samples: {recall_VADER_on_youtube_data} meaning {recall_VADER_on_youtube_data*100:.2f}%\")\n",
    "print(f\"Recall (class \\\"Positive\\\") BERT on YouTube Samples: {recall_BERT_on_youtube_data} meaning {recall_BERT_on_youtube_data*100:.2f}%\")\n",
    "print(f\"Recall (class \\\"Positive\\\") Google NLP on YouTube Samples: {recall_GoogleNLP_on_youtube_data} meaning {recall_GoogleNLP_on_youtube_data*100:.2f}%\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the Recall and the Precision score now also for the negative class. The Precision is calculated as:\n",
    "$\n",
    "\\begin{align}\n",
    "    precision = \\frac{TP}{TP + FP}\n",
    "\\end{align}\n",
    "$\n",
    "*Note: Here the Positive samples are the one with the the class `\"Negative\"`*\n",
    "\n",
    "And the Recall is calculated as:\n",
    "$\n",
    "\\begin{align}\n",
    "    recall = \\frac{TP}{TP + FN}\n",
    "\\end{align}\n",
    "$\n",
    "*Note: Here the Positive samples are the one with the the class `\"Negative\"`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code goes here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To learn more\n",
    "1. What was the best performing method for Youtube? Did that fit your expectations?\n",
    "2. What was the best performing method for Twitter? Did that fit your expectations?\n",
    "4. Do you observe any differences between prediction of positive and negative sentiment? What is the role of the imbalance between postive and negative classes in the calculation of accuracy?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "46e2835a142a16ae115bce5fddf19f27ce13b17a4ab8ded638c88ab5ce5171d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
